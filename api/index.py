"""
PraiasSP Tools - Riviera Ingestor
API Principal para processamento de relat√≥rios financeiros
"""

import os
import sys
import sqlite3
import signal
import time
import threading
from contextlib import contextmanager
from datetime import datetime

# ================================
# CONFIGURA√á√ÉO E INICIALIZA√á√ÉO
# ================================

def init_db():
    """Inicializar banco de dados com tabelas necess√°rias"""
    try:
        db_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'historico_riviera.db')
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        conn = sqlite3.connect(db_path, timeout=10)
        cursor = conn.cursor()
        
        # Tabela de movimentos financeiros
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS movimentos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                competencia TEXT NOT NULL,
                codigo_obra TEXT NOT NULL,
                obra_nome TEXT,
                tipo TEXT NOT NULL,
                valor REAL NOT NULL,
                fonte TEXT,
                data_insercao DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(competencia, codigo_obra, tipo)
            )
        ''')
        
        # Tabela de uploads
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS uploads (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                nome_arquivo TEXT NOT NULL,
                competencia TEXT,
                data_upload DATETIME DEFAULT CURRENT_TIMESTAMP,
                status TEXT DEFAULT 'processado'
            )
        ''')
        
        # Tabela de configura√ß√µes
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS configuracoes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                api_key TEXT UNIQUE,
                modelo TEXT DEFAULT 'gpt-5',
                max_tokens INTEGER DEFAULT 6000,
                chunk_size INTEGER DEFAULT 8000,
                data_atualizacao DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Tabela de or√ßamentos previstos
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS orcamento_previsto (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                codigo_obra TEXT UNIQUE NOT NULL,
                obra_nome TEXT,
                custo_previsto REAL,
                data_atualizacao DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("‚úÖ Banco de dados inicializado com sucesso")
        return True
    except Exception as e:
        print(f"‚ùå Erro ao inicializar banco: {e}")
        return False

# Pool de conex√µes para SQLite
@contextmanager
def get_db_connection():
    """Context manager para gerenciar conex√µes com banco de dados"""
    conn = None
    try:
        db_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'historico_riviera.db')
        conn = sqlite3.connect(db_path, timeout=10)
        conn.row_factory = sqlite3.Row
        yield conn
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"‚ùå Erro na conex√£o com banco: {e}")
        raise
    finally:
        if conn:
            conn.close()

# Inicializar banco
init_db()

# ================================
# IMPORTS FLASK
# ================================

from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS
from openai import OpenAI
from dotenv import load_dotenv
import gc
import json
import PyPDF2
from concurrent.futures import ThreadPoolExecutor, as_completed

# Carregar vari√°veis de ambiente
load_dotenv()

# Inicializar Flask
app = Flask(__name__, static_folder='../static', template_folder='../templates')

# Configurar CORS explicitamente
CORS(app, 
     origins=[
         "https://praias-sp-tools.vercel.app",
         "http://localhost:3000",
         "http://localhost:5173",
         "http://localhost:8080"
     ],
     methods=["GET", "POST", "OPTIONS", "PUT", "DELETE"],
     allow_headers=["Content-Type", "Authorization"],
     supports_credentials=True,
     max_age=3600
)

# Configura√ß√µes
REQUEST_TIMEOUT = 120
OPENAI_TIMEOUT = 90
UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', './uploads')
MAX_FILE_SIZE = int(os.getenv('MAX_FILE_SIZE', 52428800))  # 50MB

os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Inicializar cliente OpenAI global
openai_client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    timeout=OPENAI_TIMEOUT
)

# ================================
# MIDDLEWARE E HANDLERS
# ================================

@app.before_request
def before_request():
    """Registrar tempo de in√≠cio da requisi√ß√£o"""
    request.start_time = time.time()

@app.after_request
def after_request(response):
    """Registrar requisi√ß√µes longas e fazer limpeza + garantir CORS headers"""
    # Garantir headers CORS expl√≠citos
    origin = request.headers.get('Origin')
    allowed_origins = [
        "https://praias-sp-tools.vercel.app",
        "http://localhost:3000",
        "http://localhost:5173",
        "http://localhost:8080"
    ]
    
    if origin in allowed_origins:
        response.headers['Access-Control-Allow-Origin'] = origin
        response.headers['Access-Control-Allow-Credentials'] = 'true'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
    
    duration = time.time() - request.start_time
    if duration > 5:
        print(f"‚ö†Ô∏è Requisi√ß√£o lenta: {request.endpoint} - {duration:.2f}s")
    return response

@app.teardown_appcontext
def cleanup(exception):
    """Limpeza de mem√≥ria ap√≥s requisi√ß√£o"""
    gc.collect()

# Tratamento de sinais para graceful shutdown
def signal_handler(signum, frame):
    """Handler para sinais de encerramento"""
    print(f"\nüõë Recebido sinal {signum}. Finalizando aplica√ß√£o...")
    sys.exit(0)

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

# ================================
# ROTAS - INDEX
# ================================

@app.route('/', methods=['GET', 'HEAD'])
def index():
    """Rota raiz - verifica se API est√° online"""
    return "PraiasSP-Tools API online", 200

# ================================
# ROTAS - DADOS
# ================================

@app.route('/api/movimentos', methods=['GET'])
def get_movimentos():
    """Obter movimentos financeiros"""
    try:
        competencia = request.args.get('competencia')
        codigo_obra = request.args.get('codigo_obra')
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            query = 'SELECT * FROM movimentos WHERE 1=1'
            params = []
            
            if competencia:
                query += ' AND competencia = ?'
                params.append(competencia)
            
            if codigo_obra:
                query += ' AND codigo_obra = ?'
                params.append(codigo_obra)
            
            query += ' ORDER BY competencia DESC, codigo_obra ASC'
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            
            movimentos = [dict(row) for row in rows]
            
            return jsonify({
                'status': 'success',
                'count': len(movimentos),
                'data': movimentos
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/resumo', methods=['GET'])
def get_resumo():
    """Obter resumo consolidado"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # Resumo por obra
            cursor.execute('''
                SELECT 
                    codigo_obra,
                    obra_nome,
                    SUM(CASE WHEN tipo = 'Despesa' THEN valor ELSE 0 END) as despesas_totais,
                    SUM(CASE WHEN tipo = 'Aporte_Rateado' THEN valor ELSE 0 END) as aportes_rateados,
                    SUM(CASE WHEN tipo = 'Rentabilidade' THEN valor ELSE 0 END) as rentabilidade,
                    SUM(CASE WHEN tipo = 'Saldo_Final' THEN valor ELSE 0 END) as saldo_final
                FROM movimentos
                GROUP BY codigo_obra, obra_nome
                ORDER BY despesas_totais DESC
            ''')
            
            obras = [dict(row) for row in cursor.fetchall()]
            
            # Totais gerais
            cursor.execute('''
                SELECT 
                    SUM(CASE WHEN tipo = 'Despesa' THEN valor ELSE 0 END) as despesas_totais,
                    SUM(CASE WHEN tipo = 'Aporte_Rateado' THEN valor ELSE 0 END) as aportes_rateados,
                    SUM(CASE WHEN tipo = 'Rentabilidade' THEN valor ELSE 0 END) as rentabilidade
                FROM movimentos
            ''')
            
            totais = dict(cursor.fetchone())
            
            return jsonify({
                'status': 'success',
                'resumo': {
                    'obras': obras,
                    'totais': totais
                }
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# FUN√á√ïES AUXILIARES - PROCESSAMENTO PARALELO
# ================================

def process_single_pdf(file_obj, model):
    """
    Processa um √∫nico PDF de forma independente (para paralleliza√ß√£o)
    
    Args:
        file_obj: Objeto de arquivo
        model: Modelo a usar
    
    Returns:
        Dict com resultado ou erro
    """
    try:
        filename = file_obj.filename
        print(f"  üîÑ Iniciando: {filename}")
        
        # Extrair texto
        pdf_text = extract_pdf_text(file_obj)
        
        if not pdf_text or len(pdf_text.strip()) < 10:
            return {
                'status': 'error',
                'filename': filename,
                'message': 'PDF sem texto extra√≠vel'
            }
        
        print(f"    ‚úÖ Texto extra√≠do: {filename}")
        
        # Analisar com OpenAI
        analysis = analyze_with_openai(pdf_text, document_type='relat√≥rio financeiro', model=model)
        
        print(f"    ‚úÖ An√°lise conclu√≠da: {filename}")
        
        # Salvar no banco
        save_analysis_to_db(analysis)
        
        return {
            'status': 'success',
            'filename': filename,
            'codigo_obra': analysis.get('codigo_obra'),
            'competencia': analysis.get('competencia')
        }
    
    except Exception as e:
        print(f"    ‚ùå Erro em {file_obj.filename}: {str(e)[:100]}")
        return {
            'status': 'error',
            'filename': file_obj.filename,
            'message': str(e)[:200]
        }

# ================================
# ROTAS - UPLOAD E PROCESSAMENTO
# ================================

@app.route('/api/upload', methods=['POST'])
def upload_pdf():
    """Receber e processar m√∫ltiplos PDFs em paralelo"""
    start_time = time.time()
    
    try:
        if 'files' not in request.files:
            return jsonify({
                'status': 'error',
                'message': 'Nenhum arquivo enviado'
            }), 400
        
        files = request.files.getlist('files')
        
        if not files:
            return jsonify({
                'status': 'error',
                'message': 'Lista de arquivos vazia'
            }), 400
        
        # Obter modelo
        model = request.form.get('model', 'gpt-5')
        modelos_suportados = ['gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo']
        if model not in modelos_suportados:
            model = 'gpt-5'
        
        print(f"\n{'='*60}")
        print(f"üì¶ PROCESSAMENTO EM PARALELO DE {len(files)} PDFs")
        print(f"ü§ñ Modelo: {model}")
        print(f"‚è±Ô∏è In√≠cio: {datetime.now().strftime('%H:%M:%S')}")
        print(f"{'='*60}")
        
        # Validar e filtrar arquivos
        arquivos_validos = []
        erros_validacao = []
        
        for file in files:
            if file.filename == '':
                erros_validacao.append('Arquivo sem nome')
                continue
            
            if not file.filename.lower().endswith('.pdf'):
                erros_validacao.append(f'{file.filename} - tipo inv√°lido')
                continue
            
            if file.content_length and file.content_length > MAX_FILE_SIZE:
                erros_validacao.append(f'{file.filename} - muito grande (>{MAX_FILE_SIZE/(1024*1024)}MB)')
                continue
            
            arquivos_validos.append(file)
        
        print(f"‚úÖ {len(arquivos_validos)} arquivo(s) v√°lido(s)")
        if erros_validacao:
            print(f"‚ö†Ô∏è {len(erros_validacao)} arquivo(s) descartado(s)")
        
        # ‚≠ê PROCESSAMENTO PARALELO com ThreadPoolExecutor
        resultados = []
        erros = erros_validacao.copy()
        
        if arquivos_validos:
            print(f"\nüîÑ Iniciando processamento paralelo...")
            # Usar 3 workers (bom para 3 PDFs)
            max_workers = min(3, len(arquivos_validos))
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Submeter todos os PDFs para processamento
                futures = {
                    executor.submit(process_single_pdf, file, model): file.filename 
                    for file in arquivos_validos
                }
                
                # Coletar resultados conforme completam
                for future in as_completed(futures):
                    filename = futures[future]
                    try:
                        resultado = future.result(timeout=300)  # 5 minutos max por PDF
                        resultados.append(resultado)
                        
                        if resultado['status'] == 'error':
                            erros.append(f"{filename}: {resultado.get('message', 'Erro desconhecido')}")
                    except Exception as e:
                        erros.append(f"{filename}: {str(e)[:100]}")
        
        processing_time = time.time() - start_time
        
        print(f"\n{'='*60}")
        print(f"‚úÖ Processamento completo!")
        print(f"üìä Resultados: {len([r for r in resultados if r['status'] == 'success'])} sucesso(s)")
        if erros:
            print(f"‚ùå Erros: {len(erros)}")
        print(f"‚è±Ô∏è Tempo total: {processing_time:.2f}s")
        print(f"{'='*60}\n")
        
        return jsonify({
            'status': 'success' if resultados else 'error',
            'message': f'Processados {len(resultados)} PDF(s)',
            'model': model,
            'processados': [r for r in resultados if r['status'] == 'success'],
            'erros': erros,
            'processing_time': round(processing_time, 2)
        }), 200 if resultados else 400
    
    except Exception as e:
        processing_time = time.time() - start_time
        print(f"‚ùå ERRO GERAL: {str(e)}")
        print(f"‚è±Ô∏è Tempo at√© erro: {processing_time:.2f}s")
        return jsonify({
            'status': 'error',
            'message': f'Erro ao processar: {str(e)[:200]}',
            'processing_time': round(processing_time, 2)
        }), 500

# ================================
# ROTAS - CONFIGURA√á√ÉO
# ================================

@app.route('/api/configuracoes', methods=['GET'])
def get_configuracoes():
    """Obter configura√ß√µes"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT chave, valor FROM configuracoes')
            configuracoes = {row[0]: row[1] for row in cursor.fetchall()}
            
            return jsonify({
                'status': 'success',
                'configuracoes': configuracoes
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/configuracoes', methods=['POST'])
def atualizar_configuracoes():
    """Atualizar configura√ß√µes"""
    try:
        data = request.json
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            for chave, valor in data.items():
                cursor.execute('''
                    INSERT OR REPLACE INTO configuracoes (chave, valor)
                    VALUES (?, ?)
                ''', (chave, str(valor)))
            
            conn.commit()
        
        return jsonify({
            'status': 'success',
            'message': 'Configura√ß√µes atualizadas'
        }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# ROTAS - OR√áAMENTO PREVISTO
# ================================

@app.route('/api/orcamento', methods=['GET'])
def get_orcamento():
    """Obter or√ßamentos previstos"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT codigo_obra, obra_nome, custo_previsto
                FROM orcamento_previsto
                ORDER BY codigo_obra
            ''')
            
            orcamentos = [dict(row) for row in cursor.fetchall()]
            
            return jsonify({
                'status': 'success',
                'data': orcamentos
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/orcamento', methods=['POST'])
def atualizar_orcamento():
    """Atualizar or√ßamento previsto"""
    try:
        data = request.json
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            for item in data:
                cursor.execute('''
                    INSERT OR REPLACE INTO orcamento_previsto 
                    (codigo_obra, obra_nome, custo_previsto)
                    VALUES (?, ?, ?)
                ''', (item['codigo_obra'], item.get('obra_nome'), item['custo_previsto']))
            
            conn.commit()
        
        return jsonify({
            'status': 'success',
            'message': 'Or√ßamento atualizado'
        }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# FASE 2.1 - AN√ÅLISE COM OpenAI
# ================================

def extract_pdf_text(file):
    """Extrair texto de PDF usando PyPDF2"""
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        print(f"‚ùå Erro ao extrair PDF: {e}")
        raise

# ================================
# UTILIT√ÅRIO - COMPATIBILIDADE COM RESPONSES API (GPT-5)
# ================================

class CompatResponse:
    """Classe para compatibilidade entre Responses API (GPT-5) e Chat Completions API"""
    class Choice:
        class Message:
            def __init__(self, content):
                self.content = content
        
        def __init__(self, content):
            self.message = self.Message(content)
            self.finish_reason = "stop"
    
    def __init__(self, content):
        self.choices = [self.Choice(content)]

def process_openai_request(messages, model, max_tokens):
    """
    Processa requisi√ß√£o OpenAI com suporte a GPT-5 (Responses API) e compatibilidade com outros modelos
    
    Args:
        messages: Lista de mensagens com roles 'system' e 'user'
        model: Nome do modelo ('gpt-5', 'gpt-4o', etc)
        max_tokens: M√°ximo de tokens na resposta
    
    Returns:
        Tuple (response, error_message)
    """
    try:
        print(f"üîÑ Preparando requisi√ß√£o para {model}...")
        print(f"   Max Tokens: {max_tokens}")
        
        # ‚≠ê GPT-5 usa Responses API, n√£o Chat Completions!
        if model.startswith('gpt-5'):
            print("üîÑ Usando Responses API para GPT-5...")
            
            # Extrair system prompt e user message
            system_content = ""
            user_message = ""
            for msg in messages:
                if msg.get("role") == "system":
                    system_content = msg.get("content", "")
                elif msg.get("role") == "user":
                    user_message = msg.get("content", "")
            
            # Concatenar para Responses API (requer input √∫nico)
            combined_input = f"INSTRU√á√ïES:\n{system_content}\n\nCONTE√öDO:\n{user_message}"
            
            print(f"üìù System prompt length: {len(system_content)} chars")
            print(f"üìù User message length: {len(user_message)} chars")
            print(f"üìù Combined input length: {len(combined_input)} chars")
            
            # ‚úÖ Responses API com par√¢metros corretos para GPT-5
            # IMPORTANTE: reasoning com effort LOW para economizar tempo e mem√≥ria!
            response = openai_client.responses.create(
                model=model,
                input=combined_input,
                max_output_tokens=max_tokens,
                reasoning={"effort": "low"},  # ‚≠ê LOW, n√£o HIGH (evita timeout/mem√≥ria)
                text={"verbosity": "high"}
            )
            
            print(f"‚úÖ Resposta GPT-5 recebida | Output tokens: {max_tokens}")
            return CompatResponse(response.output_text), None
        
        else:
            # Chat Completions API para outros modelos (GPT-4o, GPT-4, etc)
            print(f"üîÑ Usando Chat Completions API para {model}...")
            
            try:
                # Tentar com max_completion_tokens (novo SDK)
                response = openai_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_completion_tokens=max_tokens,
                    temperature=0.7,
                    timeout=OPENAI_TIMEOUT
                )
                print(f"‚úÖ Usando max_completion_tokens: {max_tokens}")
                return response, None
            except TypeError:
                # Fallback para max_tokens (SDK antigo ou modelos antigos)
                response = openai_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=0.7,
                    timeout=OPENAI_TIMEOUT
                )
                print(f"‚úÖ Usando max_tokens (compatibilidade): {max_tokens}")
                return response, None
    
    except Exception as e:
        print(f"‚ùå ERRO em process_openai_request: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, str(e)

def analyze_with_openai(pdf_text, document_type='relat√≥rio', model='gpt-4o'):
    """Analisar texto com OpenAI (GPT-5, GPT-4o, etc) - L√≥gica CEO Financeiro"""
    try:
        prompt = f"""üéØ VOC√ä √â UM AUDITOR FINANCEIRO S√äNIOR - RIVIERA EMPREENDIMENTOS

MISS√ÉO CR√çTICA:
Processar PDFs mensais de Praias SP com PRECIS√ÉO ABSOLUTA. Cada n√∫mero errado custar√° MILHARES.
Voc√™ N√ÉO pode errar. Voc√™ N√ÉO pode ser vago. Voc√™ N√ÉO pode aproximar.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

IDENTIFICA√á√ÉO DO DOCUMENTO:
‚îå‚îÄ Procure nos t√≠tulos/cabe√ßalhos:
‚îÇ  ‚îú‚îÄ "POSI√á√ÉO FINANC" ‚Üí Tipo: POSICAO_FINANCEIRA (balan√ßo consolidado)
‚îÇ  ‚îú‚îÄ "DESPESAS" ‚Üí Tipo: DETALHAMENTO_DESPESAS (nota fiscal a nota fiscal)
‚îÇ  ‚îî‚îÄ C√≥digo da obra: 562, 601, 603, 604, 616, BCO, etc
‚îî‚îÄ OBRIGAT√ìRIO extrair: C√ìDIGO, TIPO, COMPET√äNCIA

EXTRA√á√ÉO OBRIGAT√ìRIA DE CAMPOS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1Ô∏è‚É£ COMPET√äNCIA (data do relat√≥rio)
   - Procure: "SETEMBRO 25", "SET 2025", "09/2025", "setembro/2025"
   - CONVERTA SEMPRE para: "09/2025"
   - SE N√ÉO ENCONTRAR: return erro "Compet√™ncia n√£o encontrada"

2Ô∏è‚É£ C√ìDIGO DA OBRA (identificador √∫nico)
   - Procure no t√≠tulo: 562, 601, 603, 604, 616, BCO, etc
   - Se houver m√∫ltiplos codes (ex: "562 601 603 e 604"), SEPARE EM 4 EXTRA√á√ïES
   - SE N√ÉO ENCONTRAR: return erro "C√≥digo n√£o encontrado"

3Ô∏è‚É£ SALDO INICIAL (sempre em n√∫mero com 2 decimais)
   - Procure: "Saldo em 31/08/2025", "Saldo Inicial", "Saldo Anterior"
   - Format: 1234567.89 (sem R$, sem separadores de milhar)
   - SE N√ÉO ENCONTRAR: "n√£o_informado"

4Ô∏è‚É£ DESPESAS DETALHADAS (CR√çTICO - n√£o aproxime)
   - Procure TODAS as linhas com valores negativos ou etiquetadas "Despesa"
   - PARA CADA DESPESA extrait:
     * descricao: "Fornecedor X - Servi√ßo Y"
     * valor: 12345.67 (exato, sem aproxima√ß√£o)
     * categoria: "Material" | "MO" | "Servicos" | "Locacao" | "Outros"
     * fornecedor: "Nome Exato do Fornecedor"
   - TOTALIZE: despesas_total = SUM(todas despesas)
   - VALIDAR: Se h√° tabelas, leia TODA a coluna de valores
   - SE HOUVER D√öVIDA: indique com "‚ö†Ô∏è" no JSON

5Ô∏è‚É£ RECEITAS (tudo que entra)
   - Aportes do pool: valor_exato
   - Rentabilidade: valor_exato
   - Reembolsos: valor_exato
   - TOTAL DE RECEITAS: receitas_total = SUM(todas receitas)

6Ô∏è‚É£ SALDO FINAL (obrigat√≥rio e preciso)
   - Procure: "Saldo em 30/09/2025", "Saldo Dispon√≠vel", "Saldo Final"
   - Format: 1234567.89
   - VALIDAR: Saldo_Final ‚âà Saldo_Inicial + Receitas - Despesas (¬±R$1,00)
   - SE DIVERG√äNCIA > R$1,00: adicione flag "saldo_auditoria_necessaria"

7Ô∏è‚É£ RATEIO DE APORTES (C√ÅLCULO AUTOM√ÅTICO)
   - Se "POSI√á√ÉO FINANCEIRA": extraia aportes_recebidos_total
   - CALCULE taxa_rateio = despesas_esta_obra / total_despesas_mes
   - CALCULE aporte_rateado = aportes_recebidos_total √ó taxa_rateio
   - Exemplo:
     * Despesas Obra 616: R$ 82,60
     * Despesas Shopping: R$ 7.319.079,56
     * Total: R$ 7.319.162,16
     * Taxa Obra 616: 82,60 / 7.319.162,16 = 0.001129%
     * Aporte recebido: R$ 5.483.433,37
     * Aporte rateado Obra 616: R$ 5.483.433,37 √ó 0.001129% = R$ XXX,XX

8Ô∏è‚É£ CONCILIA√á√ÉO BANC√ÅRIA (bandeira vermelha)
   - Procure: "Bradesco", "Saldo Banco", "Conciliado com"
   - EXTRAIA: saldo_banco_oficial, diferenca_conciliacao
   - SE diferenca > R$ 100: flag "diferenca_relevante_investigar"

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

REGRAS N√ÉO-NEGOCI√ÅVEIS:
‚ùå N√ÉO retorne narrativa, APENAS JSON
‚ùå N√ÉO aproxime valores (use valores exatos do PDF)
‚ùå N√ÉO agregue obras diferentes (cada c√≥digo √© uma extra√ß√£o separada)
‚ùå N√ÉO ignore tabelas (leia cada linha)
‚ùå N√ÉO esque√ßa decimais (sempre XX,XX)
‚ùå SE N√ÉO ENCONTRAR CAMPO: use "n√£o_informado" COM FLAG DE ALERTA

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

RETORNE ESTE JSON (sem markdown, sem explica√ß√µes):

[
  {{
    "competencia": "09/2025",
    "codigo_obra": "616",
    "nome_obra": "Extra Contratual - Fia√ß√£o Enterrada Av. Riviera Mod. 17 e 18",
    "tipo_documento": "POSICAO_FINANCEIRA",
    "saldo_inicial": 282995.57,
    "saldo_final": 355854.25,
    "despesas": [
      {{"descricao": "Descri√ß√£o exata", "valor": 123.45, "categoria": "Servicos", "fornecedor": "Nome Fornecedor"}}
    ],
    "despesas_total": 82.60,
    "receitas": [
      {{"tipo": "Aporte", "valor": 1000.00}},
      {{"tipo": "Rentabilidade", "valor": 72941.28}}
    ],
    "receitas_total": 72941.28,
    "aportes_pool": {{
      "valor_total_pool": 5483433.37,
      "despesas_todas_obras": 7319162.16,
      "taxa_rateio_esta_obra": 0.00001129,
      "valor_rateado_esta_obra": 61.87,
      "metodo_calculo": "Proporcional √†s despesas do m√™s"
    }},
    "rentabilidade_mensal": 72941.28,
    "conciliacao_bancaria": {{
      "saldo_banco": 355854.25,
      "saldo_sistema": 355854.25,
      "diferenca": 0.00,
      "status": "conciliado"
    }},
    "validacoes": {{
      "saldo_auditoria": {{"status": "OK", "diferenca_permitida": 0.00}},
      "alertas": []
    }},
    "observacoes": "Texto se houver algo relevante",
    "qualidade_extracao": "‚úÖ Completa" | "‚ö†Ô∏è Parcial - campos faltantes" | "‚ùå Erro - campo cr√≠tico ausente"
  }}
]

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

DOCUMENTO A PROCESSAR:
{pdf_text}"""
        
        messages = [
            {
                "role": "system",
                "content": "VOC√ä DEVE RETORNAR APENAS JSON V√ÅLIDO. N√ÉO RETORNE MARKDOWN, N√ÉO RETORNE NARRATIVA, N√ÉO RETORNE EXPLICA√á√ïES. APENAS JSON PURO E V√ÅLIDO."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        # Usar fun√ß√£o unificada com suporte a GPT-5
        print(f"ü§ñ Analisando com {model}...")
        response, error = process_openai_request(messages, model, max_tokens=6000)
        
        if error:
            print(f"‚ùå Erro ao chamar OpenAI: {error}")
            raise ValueError(f"Erro na API OpenAI: {error}")
        
        # Extrair conte√∫do
        response_text = response.choices[0].message.content.strip()
        
        # ‚≠ê AGRESSIVAMENTE remover markdown e narrativa
        print(f"üìù Resposta bruta ({len(response_text)} chars): {response_text[:100]}...")
        
        # Remover markdown code blocks
        if response_text.startswith('```'):
            response_text = response_text.split('```')[1]
            if response_text.startswith('json'):
                response_text = response_text[4:]
            elif response_text.startswith('\n'):
                response_text = response_text[1:]
        
        # Remover trailing markdown
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        
        # Procurar por [ ou { para come√ßar o JSON
        start_idx = response_text.find('[')
        if start_idx == -1:
            start_idx = response_text.find('{')
        
        if start_idx > 0:
            print(f"‚ö†Ô∏è Encontrou narrativa antes do JSON. Removendo primeiros {start_idx} chars...")
            response_text = response_text[start_idx:]
        
        # Procurar pelo final do JSON
        end_idx = max(response_text.rfind(']'), response_text.rfind('}'))
        if end_idx > 0 and end_idx < len(response_text) - 1:
            print(f"‚ö†Ô∏è Encontrou narrativa ap√≥s JSON. Removendo √∫ltimos {len(response_text) - end_idx - 1} chars...")
            response_text = response_text[:end_idx + 1]
        
        # Tentar parse JSON com retry
        try:
            result = json.loads(response_text)
            print(f"‚úÖ JSON parseado com sucesso!")
            return result
        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao fazer parse JSON na primeira tentativa: {e}")
            print(f"üìÑ Conte√∫do: {response_text[:200]}...")
            
            # RETRY: Se for array, tentar extrair primeiro elemento
            try:
                result = json.loads(response_text)
                return result
            except:
                raise ValueError(f"Resposta n√£o √© JSON v√°lido. Resposta: {response_text[:500]}")
    
    except json.JSONDecodeError as e:
        print(f"‚ùå Erro ao fazer parse JSON da resposta OpenAI: {e}")
        raise ValueError(f"Resposta inv√°lida do OpenAI: {str(e)}")
    except Exception as e:
        print(f"‚ùå Erro ao analisar com OpenAI: {e}")
        raise

def save_analysis_to_db(analysis):
    """Salvar an√°lise no banco de dados"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            competencia = analysis.get('competencia', 'N√£o informado')
            codigo_obra = analysis.get('codigo_obra', 'N√£o informado')
            obra_nome = analysis.get('obra_nome', 'Sem nome')
            
            # Salvar movimentos
            movimentos = analysis.get('movimentos', [])
            for mov in movimentos:
                cursor.execute('''
                    INSERT OR REPLACE INTO movimentos 
                    (competencia, codigo_obra, obra_nome, tipo, valor, fonte)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    competencia,
                    codigo_obra,
                    obra_nome,
                    mov.get('tipo', 'Outro'),
                    float(mov.get('valor', 0)),
                    mov.get('fonte', 'N√£o especificada')
                ))
            
            # Salvar arquivo processado
            cursor.execute('''
                INSERT INTO uploads (nome_arquivo, competencia, status)
                VALUES (?, ?, ?)
            ''', (f"analyzed_{codigo_obra}_{competencia}", competencia, 'processado'))
            
            conn.commit()
        
        return True
    except Exception as e:
        print(f"‚ùå Erro ao salvar an√°lise no banco: {e}")
        raise

@app.route('/api/analyze-pdf', methods=['POST'])
def analyze_pdf_endpoint():
    """
    Endpoint para an√°lise autom√°tica de PDF com OpenAI (suporta GPT-5, GPT-4o, etc)
    
    Request:
        - file: PDF file (multipart/form-data)
        - model: Modelo OpenAI (opcional, padr√£o: 'gpt-4o')
               Suportados: 'gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo'
    
    Response:
        {
            "status": "success|error",
            "data": {...an√°lise extra√≠da...},
            "model": "modelo usado",
            "message": "..."
        }
    """
    try:
        # Validar arquivo
        if 'file' not in request.files:
            return jsonify({
                'status': 'error',
                'message': 'Nenhum arquivo enviado'
            }), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({
                'status': 'error',
                'message': 'Arquivo sem nome'
            }), 400
        
        if not file.filename.lower().endswith('.pdf'):
            return jsonify({
                'status': 'error',
                'message': 'Apenas arquivos PDF s√£o aceitos'
            }), 400
        
        if file.content_length and file.content_length > MAX_FILE_SIZE:
            return jsonify({
                'status': 'error',
                'message': 'Arquivo muito grande (m√°ximo 50MB)'
            }), 400
        
        # Obter modelo do par√¢metro ou usar padr√£o
        model = request.form.get('model', 'gpt-4o')
        
        # Validar modelo
        modelos_suportados = ['gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo']
        if model not in modelos_suportados:
            print(f"‚ö†Ô∏è Modelo '{model}' n√£o suportado. Usando gpt-4o.")
            model = 'gpt-4o'
        
        print(f"üîß Modelo selecionado: {model}")
        
        # 1. Extrair texto do PDF
        print(f"üìÑ Extraindo texto de: {file.filename}")
        pdf_text = extract_pdf_text(file)
        
        if not pdf_text or len(pdf_text.strip()) < 10:
            return jsonify({
                'status': 'error',
                'message': 'PDF n√£o cont√©m texto extra√≠vel'
            }), 400
        
        print(f"‚úÖ Texto extra√≠do ({len(pdf_text)} caracteres)")
        
        # 2. Analisar com OpenAI (usando modelo selecionado)
        print(f"ü§ñ Analisando com {model}...")
        analysis = analyze_with_openai(pdf_text, document_type='relat√≥rio financeiro', model=model)
        
        print(f"‚úÖ An√°lise conclu√≠da: {analysis.get('codigo_obra')} - {analysis.get('competencia')}")
        
        # 3. Salvar no banco de dados
        print("üíæ Salvando no banco de dados...")
        save_analysis_to_db(analysis)
        
        print("‚úÖ An√°lise salva com sucesso!")
        
        return jsonify({
            'status': 'success',
            'message': f'PDF analisado com sucesso usando {model}',
            'model': model,
            'data': analysis
        }), 200
    
    except ValueError as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 400
    except Exception as e:
        print(f"‚ùå Erro ao processar PDF: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Erro ao processar PDF: {str(e)}'
        }), 500

# ================================
# ENDPOINT - CHAT COM IA (COMPAT√çVEL COM FRONTEND)
# ================================

@app.route('/api/chat', methods=['POST', 'OPTIONS'])
def chat_endpoint():
    """
    Endpoint de chat unificado com suporte a m√∫ltiplos modelos (GPT-5, GPT-4o, etc)
    
    Request (JSON):
        {
            "model": "gpt-5" (ou "gpt-4o", "gpt-4", "gpt-3.5-turbo"),
            "messages": [
                {"role": "system", "content": "..."},
                {"role": "user", "content": "..."}
            ],
            "max_tokens": 6000
        }
    
    Response:
        {
            "choices": [{
                "message": {
                    "content": "resposta da IA"
                }
            }],
            "model": "modelo usado",
            "processing_time": 1.23
        }
    """
    
    # Responder √†s requisi√ß√µes OPTIONS (preflight CORS)
    if request.method == 'OPTIONS':
        return '', 204
    
    start_time = time.time()
    
    try:
        data = request.json
        
        # Valida√ß√£o 1: Requisi√ß√£o vazia
        if not data:
            return jsonify({
                'error': 'Requisi√ß√£o vazia'
            }), 400
        
        model = data.get('model', 'gpt-5')
        messages = data.get('messages', [])
        
        # Valida√ß√£o 2: Mensagens vazias
        if not messages:
            return jsonify({
                'error': 'Nenhuma mensagem fornecida'
            }), 400
        
        # Valida√ß√£o 3: Limitar tamanho do prompt
        messages_str = str(messages)
        if len(messages_str) > 50000:
            return jsonify({
                'error': 'Prompt muito longo. M√°ximo 50k caracteres.'
            }), 400
        
        # Valida√ß√£o 4: Modelo suportado
        modelos_suportados = ['gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo']
        if model not in modelos_suportados:
            print(f"‚ö†Ô∏è Modelo '{model}' n√£o suportado. Usando padr√£o: gpt-5")
            model = 'gpt-5'
        
        # CR√çTICO: Limites por modelo (copiar exatamente da refer√™ncia)
        if model.startswith('gpt-5'):
            max_tokens = min(data.get('max_tokens', 6000), 12000)  # GPT-5: at√© 12k tokens
        else:
            max_tokens = min(data.get('max_tokens', 2000), 4000)   # Outros: at√© 4k tokens
        
        # Logging estruturado
        print("\n" + "="*60)
        print("üöÄ === NOVA REQUISI√á√ÉO DE AN√ÅLISE ===")
        print(f"üìß Modelo: {model}")
        print(f"üî¢ Max Tokens: {max_tokens}")
        print(f"üìù Total de mensagens: {len(messages)}")
        print(f"üìÑ Tamanho do prompt: {len(messages_str)} caracteres")
        print("="*60)
        
        # Chamar process_openai_request
        response, error = process_openai_request(messages, model, max_tokens)
        
        # Valida√ß√£o 5: Erro na API OpenAI
        if error:
            print(f"‚ùå ERRO na API OpenAI: {error}")
            return jsonify({
                'error': f'Erro na API OpenAI: {error}'
            }), 500
        
        # Valida√ß√£o 6: Response nulo
        if not response:
            print("‚ùå Response √© None!")
            return jsonify({
                'error': 'Resposta nula da OpenAI'
            }), 500
        
        # Valida√ß√£o 7: Choices vazio
        if not response.choices:
            print("‚ùå Response.choices vazio!")
            return jsonify({
                'error': 'Resposta vazia da OpenAI (choices vazio)'
            }), 500
        
        # Valida√ß√£o 8: Content vazio ou None
        content = response.choices[0].message.content
        if not content:
            print("‚ö†Ô∏è WARNING: Content √© None ou vazio!")
            print(f"   Finish reason: {response.choices[0].finish_reason}")
            content = "(Resposta vazia recebida da OpenAI)"
        
        processing_time = time.time() - start_time
        
        # Logging de sucesso
        print("‚úÖ Resposta da OpenAI recebida com sucesso!")
        print(f"üìÑ Tamanho da resposta: {len(content)} caracteres")
        print(f"‚è±Ô∏è Tempo de processamento: {processing_time:.2f}s")
        print("="*60 + "\n")
        
        return jsonify({
            'choices': [{
                'message': {
                    'content': content
                }
            }],
            'model': model,
            'processing_time': round(processing_time, 2)
        }), 200
    
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = f"Erro interno: {str(e)}"
        print(f"‚ùå ERRO GERAL: {error_msg}")
        print(f"‚è±Ô∏è Tempo at√© erro: {processing_time:.2f}s")
        print("="*60 + "\n")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': error_msg
        }), 500

# ================================
# ROTAS - HEALTH & STATUS
# ================================

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint com informa√ß√µes detalhadas"""
    try:
        # Testar conex√£o com banco
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM movimentos')
            total_movimentos = cursor.fetchone()[0]
            cursor.execute('SELECT COUNT(*) FROM uploads')
            total_uploads = cursor.fetchone()[0]
        
        return jsonify({
            'status': 'ok',
            'service': 'PraiasSP-Tools API',
            'timestamp': datetime.now().isoformat(),
            'openai_configured': bool(os.getenv('OPENAI_API_KEY')),
            'database': {
                'status': 'working',
                'total_movimentos': total_movimentos,
                'total_uploads': total_uploads
            },
            'configuration': {
                'request_timeout_seconds': REQUEST_TIMEOUT,
                'openai_timeout_seconds': OPENAI_TIMEOUT,
                'max_file_size_mb': MAX_FILE_SIZE / (1024 * 1024)
            }
        }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'service': 'PraiasSP-Tools API',
            'timestamp': datetime.now().isoformat(),
            'openai_configured': bool(os.getenv('OPENAI_API_KEY')),
            'database': {
                'status': 'error',
                'error': str(e)
            }
        }), 500

# ================================
# ERROR HANDLERS
# ================================

@app.errorhandler(404)
def not_found(error):
    """Tratamento de rota n√£o encontrada"""
    return jsonify({
        'status': 'error',
        'message': 'Rota n√£o encontrada'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    """Tratamento de erro interno"""
    return jsonify({
        'status': 'error',
        'message': 'Erro interno do servidor'
    }), 500

# ================================
# ENDPOINTS DE CONFIGURA√á√ïES (id√™ntico √† refer√™ncia)
# ================================

@app.route('/api/settings', methods=['GET'])
def get_settings():
    """Endpoint para recuperar configura√ß√µes do usu√°rio"""
    try:
        # Tentar obter API Key do header
        api_key = request.headers.get('X-API-Key') or request.args.get('api_key', 'default')
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                'SELECT modelo, max_tokens, chunk_size FROM configuracoes WHERE api_key = ?',
                (api_key,)
            )
            row = cursor.fetchone()
        
        if row:
            return jsonify({
                'modelo': row[0],
                'max_tokens': row[1],
                'chunk_size': row[2],
                'cached': False
            })
        else:
            # Retornar valores padr√£o se n√£o encontrado
            return jsonify({
                'modelo': 'gpt-5',
                'max_tokens': 6000,
                'chunk_size': 8000,
                'cached': True
            })
    except Exception as e:
        print(f"‚ùå Erro ao buscar configura√ß√µes: {e}")
        return jsonify({
            'modelo': 'gpt-5',
            'max_tokens': 6000,
            'chunk_size': 8000,
            'error': str(e),
            'cached': True
        }), 200  # Retornar 200 mesmo com erro para fallback

@app.route('/api/settings', methods=['POST'])
def save_settings():
    """Endpoint para salvar configura√ß√µes do usu√°rio"""
    try:
        data = request.json
        api_key = data.get('api_key', 'default')
        modelo = data.get('modelo', 'gpt-5')
        max_tokens = data.get('max_tokens', 6000)
        chunk_size = data.get('chunk_size', 8000)
        
        # Valida√ß√µes b√°sicas
        if max_tokens < 100 or max_tokens > 128000:
            return jsonify({'error': 'max_tokens deve estar entre 100 e 128000'}), 400
        
        if chunk_size < 100 or chunk_size > 128000:
            return jsonify({'error': 'chunk_size deve estar entre 100 e 128000'}), 400
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            # Tentar atualizar, sen√£o inserir (UPSERT)
            cursor.execute('''
                INSERT INTO configuracoes (api_key, modelo, max_tokens, chunk_size)
                VALUES (?, ?, ?, ?)
                ON CONFLICT(api_key) 
                DO UPDATE SET 
                    modelo = excluded.modelo,
                    max_tokens = excluded.max_tokens,
                    chunk_size = excluded.chunk_size,
                    data_atualizacao = CURRENT_TIMESTAMP
            ''', (api_key, modelo, max_tokens, chunk_size))
            conn.commit()
        
        print(f"‚úÖ Configura√ß√µes salvas para API Key: {api_key[:10]}...")
        return jsonify({
            'success': True,
            'message': 'Configura√ß√µes salvas com sucesso',
            'modelo': modelo,
            'max_tokens': max_tokens,
            'chunk_size': chunk_size
        })
    except Exception as e:
        print(f"‚ùå Erro ao salvar configura√ß√µes: {e}")
        return jsonify({'error': str(e)}), 500

# ================================
# INICIALIZA√á√ÉO
# ================================

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    app.run(
        host='0.0.0.0',
        port=port,
        debug=debug,
        use_reloader=debug
    )

"""
PraiasSP Tools - Riviera Ingestor
API Principal para processamento de relat√≥rios financeiros
"""

import os
import sys
import sqlite3
import signal
import time
import threading
from contextlib import contextmanager
from datetime import datetime

# ================================
# CONFIGURA√á√ÉO E INICIALIZA√á√ÉO
# ================================

def init_db():
    """Inicializar banco de dados com tabelas necess√°rias"""
    try:
        db_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'historico_riviera.db')
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        
        conn = sqlite3.connect(db_path, timeout=10)
        cursor = conn.cursor()
        
        # Tabela de movimentos financeiros
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS movimentos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                competencia TEXT NOT NULL,
                codigo_obra TEXT NOT NULL,
                obra_nome TEXT,
                tipo TEXT NOT NULL,
                valor REAL NOT NULL,
                fonte TEXT,
                data_insercao DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(competencia, codigo_obra, tipo)
            )
        ''')
        
        # Tabela de uploads
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS uploads (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                nome_arquivo TEXT NOT NULL,
                competencia TEXT,
                data_upload DATETIME DEFAULT CURRENT_TIMESTAMP,
                status TEXT DEFAULT 'processado'
            )
        ''')
        
        # Tabela de configura√ß√µes
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS configuracoes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                chave TEXT UNIQUE NOT NULL,
                valor TEXT,
                data_atualizacao DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Tabela de or√ßamentos previstos
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS orcamento_previsto (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                codigo_obra TEXT UNIQUE NOT NULL,
                obra_nome TEXT,
                custo_previsto REAL,
                data_atualizacao DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("‚úÖ Banco de dados inicializado com sucesso")
        return True
    except Exception as e:
        print(f"‚ùå Erro ao inicializar banco: {e}")
        return False

# Pool de conex√µes para SQLite
@contextmanager
def get_db_connection():
    """Context manager para gerenciar conex√µes com banco de dados"""
    conn = None
    try:
        db_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'historico_riviera.db')
        conn = sqlite3.connect(db_path, timeout=10)
        conn.row_factory = sqlite3.Row
        yield conn
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"‚ùå Erro na conex√£o com banco: {e}")
        raise
    finally:
        if conn:
            conn.close()

# Inicializar banco
init_db()

# ================================
# IMPORTS FLASK
# ================================

from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS
from openai import OpenAI
from dotenv import load_dotenv
import gc
import json
import PyPDF2

# Carregar vari√°veis de ambiente
load_dotenv()

# Inicializar Flask
app = Flask(__name__, static_folder='../static', template_folder='../templates')
CORS(app)

# Configura√ß√µes
REQUEST_TIMEOUT = 120
OPENAI_TIMEOUT = 90
UPLOAD_FOLDER = os.getenv('UPLOAD_FOLDER', './uploads')
MAX_FILE_SIZE = int(os.getenv('MAX_FILE_SIZE', 52428800))  # 50MB

os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Inicializar cliente OpenAI global
openai_client = OpenAI(
    api_key=os.getenv('OPENAI_API_KEY'),
    timeout=OPENAI_TIMEOUT
)

# ================================
# MIDDLEWARE E HANDLERS
# ================================

@app.before_request
def before_request():
    """Registrar tempo de in√≠cio da requisi√ß√£o"""
    request.start_time = time.time()

@app.after_request
def after_request(response):
    """Registrar requisi√ß√µes longas e fazer limpeza"""
    duration = time.time() - request.start_time
    if duration > 5:
        print(f"‚ö†Ô∏è Requisi√ß√£o lenta: {request.endpoint} - {duration:.2f}s")
    return response

@app.teardown_appcontext
def cleanup(exception):
    """Limpeza de mem√≥ria ap√≥s requisi√ß√£o"""
    gc.collect()

# Tratamento de sinais para graceful shutdown
def signal_handler(signum, frame):
    """Handler para sinais de encerramento"""
    print(f"\nüõë Recebido sinal {signum}. Finalizando aplica√ß√£o...")
    sys.exit(0)

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

# ================================
# ROTAS - HEALTH CHECK
# ================================

@app.route('/health', methods=['GET'])
def health():
    """Health check da API"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'service': 'Riviera Ingestor'
    }), 200

@app.route('/', methods=['GET', 'HEAD'])
def index():
    """Rota raiz - verifica se API est√° online"""
    return "PraiasSP-Tools API online", 200

# ================================
# ROTAS - DADOS
# ================================

@app.route('/api/movimentos', methods=['GET'])
def get_movimentos():
    """Obter movimentos financeiros"""
    try:
        competencia = request.args.get('competencia')
        codigo_obra = request.args.get('codigo_obra')
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            query = 'SELECT * FROM movimentos WHERE 1=1'
            params = []
            
            if competencia:
                query += ' AND competencia = ?'
                params.append(competencia)
            
            if codigo_obra:
                query += ' AND codigo_obra = ?'
                params.append(codigo_obra)
            
            query += ' ORDER BY competencia DESC, codigo_obra ASC'
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            
            movimentos = [dict(row) for row in rows]
            
            return jsonify({
                'status': 'success',
                'count': len(movimentos),
                'data': movimentos
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/resumo', methods=['GET'])
def get_resumo():
    """Obter resumo consolidado"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # Resumo por obra
            cursor.execute('''
                SELECT 
                    codigo_obra,
                    obra_nome,
                    SUM(CASE WHEN tipo = 'Despesa' THEN valor ELSE 0 END) as despesas_totais,
                    SUM(CASE WHEN tipo = 'Aporte_Rateado' THEN valor ELSE 0 END) as aportes_rateados,
                    SUM(CASE WHEN tipo = 'Rentabilidade' THEN valor ELSE 0 END) as rentabilidade,
                    SUM(CASE WHEN tipo = 'Saldo_Final' THEN valor ELSE 0 END) as saldo_final
                FROM movimentos
                GROUP BY codigo_obra, obra_nome
                ORDER BY despesas_totais DESC
            ''')
            
            obras = [dict(row) for row in cursor.fetchall()]
            
            # Totais gerais
            cursor.execute('''
                SELECT 
                    SUM(CASE WHEN tipo = 'Despesa' THEN valor ELSE 0 END) as despesas_totais,
                    SUM(CASE WHEN tipo = 'Aporte_Rateado' THEN valor ELSE 0 END) as aportes_rateados,
                    SUM(CASE WHEN tipo = 'Rentabilidade' THEN valor ELSE 0 END) as rentabilidade
                FROM movimentos
            ''')
            
            totais = dict(cursor.fetchone())
            
            return jsonify({
                'status': 'success',
                'resumo': {
                    'obras': obras,
                    'totais': totais
                }
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# ROTAS - UPLOAD E PROCESSAMENTO
# ================================

@app.route('/api/upload', methods=['POST'])
def upload_pdf():
    """Receber e processar PDFs"""
    try:
        if 'files' not in request.files:
            return jsonify({
                'status': 'error',
                'message': 'Nenhum arquivo enviado'
            }), 400
        
        files = request.files.getlist('files')
        
        if not files:
            return jsonify({
                'status': 'error',
                'message': 'Lista de arquivos vazia'
            }), 400
        
        processados = []
        erros = []
        
        for file in files:
            if file.filename == '':
                erros.append('Arquivo sem nome')
                continue
            
            if not file.filename.lower().endswith('.pdf'):
                erros.append(f'{file.filename} - tipo de arquivo inv√°lido')
                continue
            
            if file.content_length and file.content_length > MAX_FILE_SIZE:
                erros.append(f'{file.filename} - arquivo muito grande')
                continue
            
            try:
                # Salvar arquivo
                filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
                filepath = os.path.join(UPLOAD_FOLDER, filename)
                file.save(filepath)
                
                # Registrar no banco
                with get_db_connection() as conn:
                    cursor = conn.cursor()
                    cursor.execute('''
                        INSERT INTO uploads (nome_arquivo, status)
                        VALUES (?, ?)
                    ''', (filename, 'processando'))
                    conn.commit()
                
                processados.append({
                    'arquivo': filename,
                    'tamanho': file.content_length,
                    'status': 'recebido'
                })
            
            except Exception as e:
                erros.append(f'{file.filename} - {str(e)}')
        
        return jsonify({
            'status': 'success' if processados else 'error',
            'processados': processados,
            'erros': erros,
            'total': len(processados)
        }), 200 if processados else 400
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# ROTAS - CONFIGURA√á√ÉO
# ================================

@app.route('/api/configuracoes', methods=['GET'])
def get_configuracoes():
    """Obter configura√ß√µes"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT chave, valor FROM configuracoes')
            configuracoes = {row[0]: row[1] for row in cursor.fetchall()}
            
            return jsonify({
                'status': 'success',
                'configuracoes': configuracoes
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/configuracoes', methods=['POST'])
def atualizar_configuracoes():
    """Atualizar configura√ß√µes"""
    try:
        data = request.json
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            for chave, valor in data.items():
                cursor.execute('''
                    INSERT OR REPLACE INTO configuracoes (chave, valor)
                    VALUES (?, ?)
                ''', (chave, str(valor)))
            
            conn.commit()
        
        return jsonify({
            'status': 'success',
            'message': 'Configura√ß√µes atualizadas'
        }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# ROTAS - OR√áAMENTO PREVISTO
# ================================

@app.route('/api/orcamento', methods=['GET'])
def get_orcamento():
    """Obter or√ßamentos previstos"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT codigo_obra, obra_nome, custo_previsto
                FROM orcamento_previsto
                ORDER BY codigo_obra
            ''')
            
            orcamentos = [dict(row) for row in cursor.fetchall()]
            
            return jsonify({
                'status': 'success',
                'data': orcamentos
            }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/orcamento', methods=['POST'])
def atualizar_orcamento():
    """Atualizar or√ßamento previsto"""
    try:
        data = request.json
        
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            for item in data:
                cursor.execute('''
                    INSERT OR REPLACE INTO orcamento_previsto 
                    (codigo_obra, obra_nome, custo_previsto)
                    VALUES (?, ?, ?)
                ''', (item['codigo_obra'], item.get('obra_nome'), item['custo_previsto']))
            
            conn.commit()
        
        return jsonify({
            'status': 'success',
            'message': 'Or√ßamento atualizado'
        }), 200
    
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

# ================================
# FASE 2.1 - AN√ÅLISE COM OpenAI
# ================================

def extract_pdf_text(file):
    """Extrair texto de PDF usando PyPDF2"""
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        print(f"‚ùå Erro ao extrair PDF: {e}")
        raise

# ================================
# UTILIT√ÅRIO - COMPATIBILIDADE COM RESPONSES API (GPT-5)
# ================================

class CompatResponse:
    """Classe para compatibilidade entre Responses API (GPT-5) e Chat Completions API"""
    class Choice:
        class Message:
            def __init__(self, content):
                self.content = content
        
        def __init__(self, content):
            self.message = self.Message(content)
            self.finish_reason = "stop"
    
    def __init__(self, content):
        self.choices = [self.Choice(content)]

def process_openai_request(messages, model, max_tokens):
    """
    Processa requisi√ß√£o OpenAI com suporte a GPT-5 (Responses API) e compatibilidade com outros modelos
    
    Args:
        messages: Lista de mensagens com roles 'system' e 'user'
        model: Nome do modelo ('gpt-5', 'gpt-4o', etc)
        max_tokens: M√°ximo de tokens na resposta
    
    Returns:
        Tuple (response, error_message)
    """
    try:
        print(f"üîÑ Preparando requisi√ß√£o para {model}...")
        print(f"   Max Tokens: {max_tokens}")
        
        # ‚≠ê GPT-5 usa Responses API, n√£o Chat Completions!
        if model.startswith('gpt-5'):
            print("üîÑ Usando Responses API para GPT-5...")
            
            # Extrair system prompt e user message
            system_content = ""
            user_message = ""
            for msg in messages:
                if msg.get("role") == "system":
                    system_content = msg.get("content", "")
                elif msg.get("role") == "user":
                    user_message = msg.get("content", "")
            
            # Concatenar para Responses API (requer input √∫nico)
            combined_input = f"INSTRU√á√ïES:\n{system_content}\n\nCONTE√öDO:\n{user_message}"
            
            print(f"üìù System prompt length: {len(system_content)} chars")
            print(f"üìù User message length: {len(user_message)} chars")
            print(f"üìù Combined input length: {len(combined_input)} chars")
            
            # ‚úÖ Responses API com par√¢metros corretos para GPT-5
            response = openai_client.responses.create(
                model=model,
                input=combined_input,
                max_output_tokens=max_tokens,
                reasoning={"effort": "low"},  # Baixo esfor√ßo para velocidade
                text={"verbosity": "high"}  # Alta verbosidade para an√°lise completa
            )
            
            print(f"‚úÖ Resposta GPT-5 recebida | Output tokens: {max_tokens}")
            
            # Converter para formato compat√≠vel com Chat Completions
            return CompatResponse(response.output_text), None
        
        else:
            # Chat Completions API para outros modelos (GPT-4o, GPT-4, etc)
            print(f"üîÑ Usando Chat Completions API para {model}...")
            
            try:
                # Tentar com max_completion_tokens (novo SDK)
                response = openai_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_completion_tokens=max_tokens,
                    temperature=0.7,
                    timeout=OPENAI_TIMEOUT
                )
                print(f"‚úÖ Usando max_completion_tokens: {max_tokens}")
                return response, None
            except TypeError:
                # Fallback para max_tokens (SDK antigo ou modelos antigos)
                response = openai_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=0.7,
                    timeout=OPENAI_TIMEOUT
                )
                print(f"‚úÖ Usando max_tokens (compatibilidade): {max_tokens}")
                return response, None
    
    except Exception as e:
        print(f"‚ùå ERRO em process_openai_request: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, str(e)

def analyze_with_openai(pdf_text, document_type='relat√≥rio', model='gpt-4o'):
    """Analisar texto com OpenAI (GPT-5, GPT-4o, etc) - L√≥gica CEO Financeiro"""
    try:
        prompt = f"""üéØ VOC√ä √â UM AUDITOR FINANCEIRO S√äNIOR - RIVIERA EMPREENDIMENTOS

MISS√ÉO CR√çTICA:
Processar PDFs mensais de Praias SP com PRECIS√ÉO ABSOLUTA. Cada n√∫mero errado custar√° MILHARES.
Voc√™ N√ÉO pode errar. Voc√™ N√ÉO pode ser vago. Voc√™ N√ÉO pode aproximar.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

IDENTIFICA√á√ÉO DO DOCUMENTO:
‚îå‚îÄ Procure nos t√≠tulos/cabe√ßalhos:
‚îÇ  ‚îú‚îÄ "POSI√á√ÉO FINANC" ‚Üí Tipo: POSICAO_FINANCEIRA (balan√ßo consolidado)
‚îÇ  ‚îú‚îÄ "DESPESAS" ‚Üí Tipo: DETALHAMENTO_DESPESAS (nota fiscal a nota fiscal)
‚îÇ  ‚îî‚îÄ C√≥digo da obra: 562, 601, 603, 604, 616, BCO, etc
‚îî‚îÄ OBRIGAT√ìRIO extrair: C√ìDIGO, TIPO, COMPET√äNCIA

EXTRA√á√ÉO OBRIGAT√ìRIA DE CAMPOS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1Ô∏è‚É£ COMPET√äNCIA (data do relat√≥rio)
   - Procure: "SETEMBRO 25", "SET 2025", "09/2025", "setembro/2025"
   - CONVERTA SEMPRE para: "09/2025"
   - SE N√ÉO ENCONTRAR: return erro "Compet√™ncia n√£o encontrada"

2Ô∏è‚É£ C√ìDIGO DA OBRA (identificador √∫nico)
   - Procure no t√≠tulo: 562, 601, 603, 604, 616, BCO, etc
   - Se houver m√∫ltiplos codes (ex: "562 601 603 e 604"), SEPARE EM 4 EXTRA√á√ïES
   - SE N√ÉO ENCONTRAR: return erro "C√≥digo n√£o encontrado"

3Ô∏è‚É£ SALDO INICIAL (sempre em n√∫mero com 2 decimais)
   - Procure: "Saldo em 31/08/2025", "Saldo Inicial", "Saldo Anterior"
   - Format: 1234567.89 (sem R$, sem separadores de milhar)
   - SE N√ÉO ENCONTRAR: "n√£o_informado"

4Ô∏è‚É£ DESPESAS DETALHADAS (CR√çTICO - n√£o aproxime)
   - Procure TODAS as linhas com valores negativos ou etiquetadas "Despesa"
   - PARA CADA DESPESA extrait:
     * descricao: "Fornecedor X - Servi√ßo Y"
     * valor: 12345.67 (exato, sem aproxima√ß√£o)
     * categoria: "Material" | "MO" | "Servicos" | "Locacao" | "Outros"
     * fornecedor: "Nome Exato do Fornecedor"
   - TOTALIZE: despesas_total = SUM(todas despesas)
   - VALIDAR: Se h√° tabelas, leia TODA a coluna de valores
   - SE HOUVER D√öVIDA: indique com "‚ö†Ô∏è" no JSON

5Ô∏è‚É£ RECEITAS (tudo que entra)
   - Aportes do pool: valor_exato
   - Rentabilidade: valor_exato
   - Reembolsos: valor_exato
   - TOTAL DE RECEITAS: receitas_total = SUM(todas receitas)

6Ô∏è‚É£ SALDO FINAL (obrigat√≥rio e preciso)
   - Procure: "Saldo em 30/09/2025", "Saldo Dispon√≠vel", "Saldo Final"
   - Format: 1234567.89
   - VALIDAR: Saldo_Final ‚âà Saldo_Inicial + Receitas - Despesas (¬±R$1,00)
   - SE DIVERG√äNCIA > R$1,00: adicione flag "saldo_auditoria_necessaria"

7Ô∏è‚É£ RATEIO DE APORTES (C√ÅLCULO AUTOM√ÅTICO)
   - Se "POSI√á√ÉO FINANCEIRA": extraia aportes_recebidos_total
   - CALCULE taxa_rateio = despesas_esta_obra / total_despesas_mes
   - CALCULE aporte_rateado = aportes_recebidos_total √ó taxa_rateio
   - Exemplo:
     * Despesas Obra 616: R$ 82,60
     * Despesas Shopping: R$ 7.319.079,56
     * Total: R$ 7.319.162,16
     * Taxa Obra 616: 82,60 / 7.319.162,16 = 0.001129%
     * Aporte recebido: R$ 5.483.433,37
     * Aporte rateado Obra 616: R$ 5.483.433,37 √ó 0.001129% = R$ XXX,XX

8Ô∏è‚É£ CONCILIA√á√ÉO BANC√ÅRIA (bandeira vermelha)
   - Procure: "Bradesco", "Saldo Banco", "Conciliado com"
   - EXTRAIA: saldo_banco_oficial, diferenca_conciliacao
   - SE diferenca > R$ 100: flag "diferenca_relevante_investigar"

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

REGRAS N√ÉO-NEGOCI√ÅVEIS:
‚ùå N√ÉO retorne narrativa, APENAS JSON
‚ùå N√ÉO aproxime valores (use valores exatos do PDF)
‚ùå N√ÉO agregue obras diferentes (cada c√≥digo √© uma extra√ß√£o separada)
‚ùå N√ÉO ignore tabelas (leia cada linha)
‚ùå N√ÉO esque√ßa decimais (sempre XX,XX)
‚ùå SE N√ÉO ENCONTRAR CAMPO: use "n√£o_informado" COM FLAG DE ALERTA

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

RETORNE ESTE JSON (sem markdown, sem explica√ß√µes):

[
  {{
    "competencia": "09/2025",
    "codigo_obra": "616",
    "nome_obra": "Extra Contratual - Fia√ß√£o Enterrada Av. Riviera Mod. 17 e 18",
    "tipo_documento": "POSICAO_FINANCEIRA",
    "saldo_inicial": 282995.57,
    "saldo_final": 355854.25,
    "despesas": [
      {{"descricao": "Descri√ß√£o exata", "valor": 123.45, "categoria": "Servicos", "fornecedor": "Nome Fornecedor"}}
    ],
    "despesas_total": 82.60,
    "receitas": [
      {{"tipo": "Aporte", "valor": 1000.00}},
      {{"tipo": "Rentabilidade", "valor": 72941.28}}
    ],
    "receitas_total": 72941.28,
    "aportes_pool": {{
      "valor_total_pool": 5483433.37,
      "despesas_todas_obras": 7319162.16,
      "taxa_rateio_esta_obra": 0.00001129,
      "valor_rateado_esta_obra": 61.87,
      "metodo_calculo": "Proporcional √†s despesas do m√™s"
    }},
    "rentabilidade_mensal": 72941.28,
    "conciliacao_bancaria": {{
      "saldo_banco": 355854.25,
      "saldo_sistema": 355854.25,
      "diferenca": 0.00,
      "status": "conciliado"
    }},
    "validacoes": {{
      "saldo_auditoria": {{"status": "OK", "diferenca_permitida": 0.00}},
      "alertas": []
    }},
    "observacoes": "Texto se houver algo relevante",
    "qualidade_extracao": "‚úÖ Completa" | "‚ö†Ô∏è Parcial - campos faltantes" | "‚ùå Erro - campo cr√≠tico ausente"
  }}
]

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

DOCUMENTO A PROCESSAR:
{pdf_text}"""
        
        messages = [
            {
                "role": "system",
                "content": "Retorne APENAS JSON v√°lido, sem markdown."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        # Usar fun√ß√£o unificada com suporte a GPT-5
        print(f"ü§ñ Analisando com {model}...")
        response, error = process_openai_request(messages, model, max_tokens=2000)
        
        if error:
            print(f"‚ùå Erro ao chamar OpenAI: {error}")
            raise ValueError(f"Erro na API OpenAI: {error}")
        
        # Extrair conte√∫do e fazer parse JSON
        response_text = response.choices[0].message.content.strip()
        
        # Remover markdown code blocks se existirem
        if response_text.startswith('```'):
            response_text = response_text.split('```')[1]
            if response_text.startswith('json'):
                response_text = response_text[4:]
        
        result = json.loads(response_text)
        return result
    
    except json.JSONDecodeError as e:
        print(f"‚ùå Erro ao fazer parse JSON da resposta OpenAI: {e}")
        raise ValueError(f"Resposta inv√°lida do OpenAI: {str(e)}")
    except Exception as e:
        print(f"‚ùå Erro ao analisar com OpenAI: {e}")
        raise

def save_analysis_to_db(analysis):
    """Salvar an√°lise no banco de dados"""
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            competencia = analysis.get('competencia', 'N√£o informado')
            codigo_obra = analysis.get('codigo_obra', 'N√£o informado')
            obra_nome = analysis.get('obra_nome', 'Sem nome')
            
            # Salvar movimentos
            movimentos = analysis.get('movimentos', [])
            for mov in movimentos:
                cursor.execute('''
                    INSERT OR REPLACE INTO movimentos 
                    (competencia, codigo_obra, obra_nome, tipo, valor, fonte)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    competencia,
                    codigo_obra,
                    obra_nome,
                    mov.get('tipo', 'Outro'),
                    float(mov.get('valor', 0)),
                    mov.get('fonte', 'N√£o especificada')
                ))
            
            # Salvar arquivo processado
            cursor.execute('''
                INSERT INTO uploads (nome_arquivo, competencia, status)
                VALUES (?, ?, ?)
            ''', (f"analyzed_{codigo_obra}_{competencia}", competencia, 'processado'))
            
            conn.commit()
        
        return True
    except Exception as e:
        print(f"‚ùå Erro ao salvar an√°lise no banco: {e}")
        raise

@app.route('/api/analyze-pdf', methods=['POST'])
def analyze_pdf_endpoint():
    """
    Endpoint para an√°lise autom√°tica de PDF com OpenAI (suporta GPT-5, GPT-4o, etc)
    
    Request:
        - file: PDF file (multipart/form-data)
        - model: Modelo OpenAI (opcional, padr√£o: 'gpt-4o')
               Suportados: 'gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo'
    
    Response:
        {
            "status": "success|error",
            "data": {...an√°lise extra√≠da...},
            "model": "modelo usado",
            "message": "..."
        }
    """
    try:
        # Validar arquivo
        if 'file' not in request.files:
            return jsonify({
                'status': 'error',
                'message': 'Nenhum arquivo enviado'
            }), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({
                'status': 'error',
                'message': 'Arquivo sem nome'
            }), 400
        
        if not file.filename.lower().endswith('.pdf'):
            return jsonify({
                'status': 'error',
                'message': 'Apenas arquivos PDF s√£o aceitos'
            }), 400
        
        if file.content_length and file.content_length > MAX_FILE_SIZE:
            return jsonify({
                'status': 'error',
                'message': 'Arquivo muito grande (m√°ximo 50MB)'
            }), 400
        
        # Obter modelo do par√¢metro ou usar padr√£o
        model = request.form.get('model', 'gpt-4o')
        
        # Validar modelo
        modelos_suportados = ['gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo']
        if model not in modelos_suportados:
            print(f"‚ö†Ô∏è Modelo '{model}' n√£o suportado. Usando gpt-4o.")
            model = 'gpt-4o'
        
        print(f"üîß Modelo selecionado: {model}")
        
        # 1. Extrair texto do PDF
        print(f"üìÑ Extraindo texto de: {file.filename}")
        pdf_text = extract_pdf_text(file)
        
        if not pdf_text or len(pdf_text.strip()) < 10:
            return jsonify({
                'status': 'error',
                'message': 'PDF n√£o cont√©m texto extra√≠vel'
            }), 400
        
        print(f"‚úÖ Texto extra√≠do ({len(pdf_text)} caracteres)")
        
        # 2. Analisar com OpenAI (usando modelo selecionado)
        print(f"ü§ñ Analisando com {model}...")
        analysis = analyze_with_openai(pdf_text, document_type='relat√≥rio financeiro', model=model)
        
        print(f"‚úÖ An√°lise conclu√≠da: {analysis.get('codigo_obra')} - {analysis.get('competencia')}")
        
        # 3. Salvar no banco de dados
        print("üíæ Salvando no banco de dados...")
        save_analysis_to_db(analysis)
        
        print("‚úÖ An√°lise salva com sucesso!")
        
        return jsonify({
            'status': 'success',
            'message': f'PDF analisado com sucesso usando {model}',
            'model': model,
            'data': analysis
        }), 200
    
    except ValueError as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 400
    except Exception as e:
        print(f"‚ùå Erro ao processar PDF: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'Erro ao processar PDF: {str(e)}'
        }), 500

# ================================
# ENDPOINT - CHAT COM IA (COMPAT√çVEL COM FRONTEND)
# ================================

@app.route('/api/chat', methods=['POST'])
def chat_endpoint():
    """
    Endpoint de chat unificado com suporte a m√∫ltiplos modelos (GPT-5, GPT-4o, etc)
    
    Request (JSON):
        {
            "model": "gpt-4o" (ou "gpt-5", "gpt-4", "gpt-3.5-turbo"),
            "messages": [
                {"role": "system", "content": "..."},
                {"role": "user", "content": "..."}
            ],
            "max_tokens": 2000
        }
    
    Response:
        {
            "choices": [{
                "message": {
                    "content": "resposta da IA"
                }
            }],
            "model": "modelo usado",
            "tokens_info": {...}
        }
    """
    try:
        data = request.json
        
        if not data:
            return jsonify({
                'error': 'Requisi√ß√£o vazia'
            }), 400
        
        model = data.get('model', 'gpt-4o')
        messages = data.get('messages', [])
        max_tokens = data.get('max_tokens', 2000)
        
        # Validar modelo
        modelos_suportados = ['gpt-5', 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo']
        if model not in modelos_suportados:
            model = 'gpt-4o'
            print(f"‚ö†Ô∏è Modelo inv√°lido. Usando padr√£o: {model}")
        
        print(f"üí¨ Chat endpoint chamado")
        print(f"   Modelo: {model}")
        print(f"   Mensagens: {len(messages)}")
        print(f"   Max tokens: {max_tokens}")
        
        # Chamar process_openai_request
        response, error = process_openai_request(messages, model, max_tokens)
        
        if error:
            print(f"‚ùå Erro ao processar requisi√ß√£o: {error}")
            return jsonify({
                'error': error
            }), 500
        
        # Formatar resposta compat√≠vel com frontend
        content = response.choices[0].message.content
        
        print(f"‚úÖ Resposta gerada ({len(content)} chars)")
        
        return jsonify({
            'choices': [{
                'message': {
                    'content': content
                }
            }],
            'model': model,
            'tokens_info': {
                'max_tokens': max_tokens
            }
        }), 200
    
    except Exception as e:
        print(f"‚ùå Erro no endpoint /api/chat: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': str(e)
        }), 500

# ================================
# ERROR HANDLERS
# ================================

@app.errorhandler(404)
def not_found(error):
    """Tratamento de rota n√£o encontrada"""
    return jsonify({
        'status': 'error',
        'message': 'Rota n√£o encontrada'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    """Tratamento de erro interno"""
    return jsonify({
        'status': 'error',
        'message': 'Erro interno do servidor'
    }), 500

# ================================
# INICIALIZA√á√ÉO
# ================================

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    app.run(
        host='0.0.0.0',
        port=port,
        debug=debug,
        use_reloader=debug
    )
